<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <title>A/B Testing Project</title>
</head>
<body>
    <header>
        <h1>A/B Testing Project</h1>
        <p>An analysis of user interaction with different UI designs</p>
    </header>
    <main>
        <section id="overview">
            <h2>Project Overview</h2>
            <p>The objective of this project was to perform A/B testing on two distinct versions of a webpage's UI design and scrutinize the outcomes to ascertain the efficacy of each design in fostering user interaction. Users were tasked with scheduling a Primary Care Visit appointment with Adam Ng, MD at Morristown Medical Center on April 23, 2024, on both Website A and Website B. Minor modifications were implemented solely on Website B.</p>
        </section>
        <section id="modifications">
            <h2>Webpage Modifications</h2>
            <img src="BWebsite.png" width="500" alt="Screenshot of modified webpage">
            <p>The changes made in the Version B site are aimed at enhancing clarity and visual hierarchy in the appointment scheduling section:</p>
            <ul>
                <li><strong>Clear Division between Navigation and Appointment Scheduling:</strong> To improve visual separation between the navigation bars (side and top) and the appointment scheduling section, a slightly darker color scheme was applied to the appointment scheduling area. This change helps users quickly distinguish between the navigation elements and the content related to appointment management.</li>
                <li><strong>Revised Layout for Appointment Information:</strong> The layout of appointment information was adjusted to provide a clearer correlation between the date, doctor, and location details. By arranging the buttons ("See Appointment" and "Schedule Appointment") side by side, users are better able to associate each button with its corresponding appointment details. This layout refinement contributes to a more intuitive user experience, facilitating easier navigation and interaction within the scheduling interface.</li>
            </ul>
        </section>

        <section id="results">
            <h2>Hypotheses</h2>
            <p>Below are the null and alternative hypotheses for the metrics tested:</p>
            <div class="hypothesis">
                <u><h3>Misclick Rate</h3></u>
                <p><strong>Null Hypothesis:</strong> The misclick rate is the same for both versions of the website.</p>
                <p><strong>Alternative Hypothesis:</strong> The misclick rate is lower for Version B compared to Version A.</p>
            </div>
            <div class="hypothesis">
                <u><h3>Time on Page</h3></u>
                <p><strong>Null Hypothesis:</strong> The time spent on the webpage is the same for both versions of the website.</p>
                <p><strong>Alternative Hypothesis:</strong> The time spent on the webpage is lower for Version B compared to Version A.</p>
            </div>
            <div class="hypothesis">
                <u><h3>Number of Clicks</h3></u>
                <p><strong>Null Hypothesis:</strong> The number of clicks is the same for both versions of the website.</p>
                <p><strong>Alternative Hypothesis:</strong> The number of clicks is different for Version B compared to Version A.</p>
            </div>
        </section>
        <section id="hypotheses">
            <h2>Results</h2>
            <div class="result">
                <h3 class="result-heading">Misclick Rate</h3>
                <p><span class="highlight">Test Used:</span> Chi-squared test</p>
                <p><span class="highlight">Explanation:</span> The Chi-squared test was selected to compare the misclick rates between versions A and B because it is appropriate for analyzing categorical data, such as whether a user misclicked or not. This test assesses the association between two categorical variables and determines if any observed differences are statistically significant.</p>
                <p><span class="highlight">Result:</span> p-value = 0.034 (assuming significance level α = 0.05)</p>
                <p><span class="highlight">Interpretation:</span> The difference in misclick rates between versions A and B is statistically significant.</p>
                <p><span class="highlight">Conclusion:</span> Reject the null hypothesis. Version B has a lower misclick rate compared to version A.</p>

            </div>
            <div class="result">
                <h3 class="result-heading">Time on Page</h3>
                <p><span class="highlight">Test Used:</span> Two-tailed t-test</p>
                <p><span class="highlight">Explanation:</span> The two-tailed t-test was chosen to compare the time spent on the webpage between versions A and B. This test is suitable for comparing means between two groups, making it ideal for analyzing continuous variables like time. It helps determine if the observed difference in time on page between versions is statistically significant.</p>
                <p><span class="highlight">Result:</span> t-value = -2.12, p-value = 0.039 (assuming significance level α = 0.05)</p>
                <p><span class="highlight">Interpretation:</span> The difference in time spent on the webpage between versions A and B is statistically significant.</p>
                <p><span class="highlight">Conclusion:</span> Reject the null hypothesis. Users spend less time on the webpage in version B compared to version A.</p>

            </div>
            <div class="result">
                <h3 class="result-heading">Number of Clicks</h3>
                <p><span class="highlight">Test Used:</span> Two-tailed t-test</p>
                <p><span class="highlight">Explanation:</span> Similar to the time on page test, the two-tailed t-test was employed to compare the number of clicks between versions A and B. This test allows us to assess if there is a statistically significant difference in the mean number of clicks between the two versions. It is appropriate for continuous variables like the number of clicks and helps in determining the significance of observed differences.</p>
                <p><span class="highlight">Result:</span> t-value = 1.89, p-value = 0.074 (assuming significance level α = 0.05)</p>
                <p><span class="highlight">Interpretation:</span> The difference in the number of clicks between versions A and B is not statistically significant.</p>
                <p><span class="highlight">Conclusion:</span> Fail to reject the null hypothesis. There is no significant difference in the number of clicks between versions A and B.</p>

            </div>
        </section>
        <section id="summary">
            <h2>Summary Statistics</h2>
            <p>Summary statistics provide insights into user behavior and interaction patterns:</p>
            <ul>
                <li>We collected data from 24 users for version A and 20 users for version B.</li>
                <br>
                <li>The mean time on page for version A was 17866.0 milliseconds (17.9 seconds), while for version B, it was 8140.85 milliseconds (8.1 seconds).<strong>This suggests that users tended to spend less time on version B compared to version A.</strong></li>
                <br>
                <li>The median number of clicks for version A was 2.0, and for version B, it was 2.0. In other words, The typical user clicked on elements of the website about 2 times during their session for both version A and version B. <strong>This means that most users interacted with the website by clicking about twice, regardless of which version they were using.</strong></li>
            </ul>
        </section>

        <section id="recommendations">
            <h2>Recommendations</h2>
            <p>Based on the findings of the A/B testing, the following recommendations can be made to optimize user interaction:</p>
            <ul>
                <li><strong>Implement Version B Changes:</strong> Since Version B showed a lower misclick rate and reduced time spent on the webpage, consider implementing the modifications made in Version B across the entire website to enhance user experience.</li>
                <li><strong>User Feedback Integration:</strong> Gather user feedback through surveys or feedback forms to gain insights into specific pain points or areas for improvement, then incorporate this feedback into future design iterations.</li>
                <li><strong>Regular Monitoring:</strong> Establish a system for regularly monitoring user interaction metrics to promptly identify any emerging issues or opportunities for optimization.</li>
            </ul>
            <br>
            <br>
            </section>
    </main>
    <footer>
        <p>&copy; 2024 A/B Testing Project</p>
    </footer>
</body>
</html>
